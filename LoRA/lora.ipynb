{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "jq4rv-H9A1E3"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from dataclasses import dataclass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "iP7oO5C8A1E4"
      },
      "outputs": [],
      "source": [
        "@dataclass\n",
        "class ModelArgs:\n",
        "    device: str = 'cuda'\n",
        "    epochs: int = 5\n",
        "    max_lr: float = 2e-5\n",
        "    rank: int = 4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aVPXm1KSBC0t",
        "outputId": "ce4d741a-a6be-4a87-d16d-126c0a5fb86a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (3.2.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.17.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (1.26.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (17.0.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2024.9.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.11)\n",
            "Requirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.27.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (24.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.18.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.23.0->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2024.12.14)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install datasets\n",
        "# !pip install evaluate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "05L0rZuEA1E6"
      },
      "outputs": [],
      "source": [
        "\n",
        "import os\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "\n",
        "from google.colab import userdata\n",
        "HF_TOKEN=userdata.get('HF_TOKEN')\n",
        "\n",
        "model_id = \"openai-community/gpt2\"\n",
        "\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_id, token=HF_TOKEN)\n",
        "model = AutoModelForCausalLM.from_pretrained(model_id, device_map=\"auto\", token=HF_TOKEN)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LhfiL1KzgiKF",
        "outputId": "27742fd9-7b94-4df1-8cf4-78386df00616"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "GPT2Config {\n",
              "  \"_attn_implementation_autoset\": true,\n",
              "  \"_name_or_path\": \"openai-community/gpt2\",\n",
              "  \"activation_function\": \"gelu_new\",\n",
              "  \"architectures\": [\n",
              "    \"GPT2LMHeadModel\"\n",
              "  ],\n",
              "  \"attn_pdrop\": 0.1,\n",
              "  \"bos_token_id\": 50256,\n",
              "  \"embd_pdrop\": 0.1,\n",
              "  \"eos_token_id\": 50256,\n",
              "  \"initializer_range\": 0.02,\n",
              "  \"layer_norm_epsilon\": 1e-05,\n",
              "  \"model_type\": \"gpt2\",\n",
              "  \"n_ctx\": 1024,\n",
              "  \"n_embd\": 768,\n",
              "  \"n_head\": 12,\n",
              "  \"n_inner\": null,\n",
              "  \"n_layer\": 12,\n",
              "  \"n_positions\": 1024,\n",
              "  \"reorder_and_upcast_attn\": false,\n",
              "  \"resid_pdrop\": 0.1,\n",
              "  \"scale_attn_by_inverse_layer_idx\": false,\n",
              "  \"scale_attn_weights\": true,\n",
              "  \"summary_activation\": null,\n",
              "  \"summary_first_dropout\": 0.1,\n",
              "  \"summary_proj_to_labels\": true,\n",
              "  \"summary_type\": \"cls_index\",\n",
              "  \"summary_use_proj\": true,\n",
              "  \"task_specific_params\": {\n",
              "    \"text-generation\": {\n",
              "      \"do_sample\": true,\n",
              "      \"max_length\": 50\n",
              "    }\n",
              "  },\n",
              "  \"transformers_version\": \"4.47.1\",\n",
              "  \"use_cache\": true,\n",
              "  \"vocab_size\": 50257\n",
              "}"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "svcw4Q9HklQj",
        "outputId": "a5ef189e-1b5f-4ac1-acfb-1c8cb72dd7b9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2025-01-24 23:42:04--  https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.109.133, 185.199.108.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1115394 (1.1M) [text/plain]\n",
            "Saving to: ‘input.txt.2’\n",
            "\n",
            "input.txt.2         100%[===================>]   1.06M  --.-KB/s    in 0.05s   \n",
            "\n",
            "2025-01-24 23:42:05 (21.7 MB/s) - ‘input.txt.2’ saved [1115394/1115394]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#Collab setup\n",
        "from pathlib import Path\n",
        "data_path = Path('/content/data')\n",
        "data_path.mkdir(exist_ok=True)\n",
        "!wget https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\n",
        "!cp input.txt data/input.txt\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "FYDAFB3Ykn1j"
      },
      "outputs": [],
      "source": [
        "#Datasets\n",
        "\n",
        "# Using tinyshakespeare\n",
        "\n",
        "with open('/content/data/input.txt', 'r', encoding='utf-8') as f:\n",
        "    text = f.read()\n",
        "\n",
        "####################################################################\n",
        "\n",
        "#Using BookCorpus\n",
        "# from datasets import load_dataset\n",
        "# data = load_dataset('bookcorpus/bookcorpus')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "iWgRTwtpkn4X"
      },
      "outputs": [],
      "source": [
        "\n",
        "#Loading custom trained BPE\n",
        "# Load the tokenizer\n",
        "# tokenizer = Tokenizer.from_file(\"bpe_tokenizer_tinyshakespeare_20k.json\")\n",
        "# vocab_size = tokenizer.get_vocab_size()\n",
        "# Encode and decode functions\n",
        "# encode = lambda s: tokenizer.encode(s).ids\n",
        "# decode = lambda l: tokenizer.decode(l)\n",
        "\n",
        "###############################################################################\n",
        "#Character level tokenization\n",
        "\n",
        "# # here are all the unique characters that occur in this text\n",
        "chars = sorted(list(set(text)))\n",
        "vocab_size = len(chars)\n",
        "\n",
        "\n",
        "# create a mapping from characters to integers\n",
        "stoi = { ch: i for i,ch in enumerate(chars) }\n",
        "itos = { i:ch for i,ch in enumerate(chars) }\n",
        "encode = lambda s: [stoi[c] for c in s] # encoder: take a string, output a list of integers\n",
        "decode = lambda l: ''.join([itos[i] for i in l]) # decoder: take a list of integers, output a string\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "TbjLimHvk4Eo"
      },
      "outputs": [],
      "source": [
        "# Train and test splits\n",
        "data = torch.tensor(encode(text), dtype=torch.long)\n",
        "n = int(0.9*len(data)) # first 90% will be train, rest val\n",
        "train_data = data[:n]\n",
        "val_data = data[n:]\n",
        "block_size = 1024\n",
        "batch_size = 4\n",
        "# data loading\n",
        "def get_batch(split):\n",
        "    # generate a small batch of data of inputs x and targets y\n",
        "    data = train_data if split == 'train' else val_data\n",
        "    ix = torch.randint(len(data) - block_size, (batch_size,))\n",
        "    x = torch.stack([data[i:i+block_size] for i in ix])\n",
        "    y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
        "    x, y = x.to(ModelArgs.device), y.to(ModelArgs.device)\n",
        "    return x, y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "_QJtn4C5A1E7"
      },
      "outputs": [],
      "source": [
        "count = 0\n",
        "\n",
        "count = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "6kH3dS2LA1E7"
      },
      "outputs": [],
      "source": [
        "class LoRALayer(nn.Module):\n",
        "    def __init__(self) -> None:\n",
        "        super().__init__()\n",
        "\n",
        "\n",
        "        self.rank = ModelArgs.rank\n",
        "        self.model_weight_dims = model.config.n_embd\n",
        "        self.query_A = nn.Parameter(torch.ones((self.model_weight_dims, self.rank), requires_grad=True))\n",
        "        self.query_B = nn.Parameter(torch.zeros((self.rank, self.model_weight_dims), requires_grad=True))\n",
        "        self.key_A = nn.Parameter(torch.ones((self.model_weight_dims, self.rank), requires_grad=True))\n",
        "        self.key_B = nn.Parameter(torch.zeros((self.rank, self.model_weight_dims), requires_grad=True))\n",
        "        self.value_A = nn.Parameter(torch.ones((self.model_weight_dims, self.rank), requires_grad=True))\n",
        "        self.value_B = nn.Parameter(torch.zeros((self.rank, self.model_weight_dims), requires_grad=True))\n",
        "        self.output_A = nn.Parameter(torch.ones((self.model_weight_dims, self.rank), requires_grad=True))\n",
        "        self.output_B = nn.Parameter(torch.zeros((self.rank, self.model_weight_dims), requires_grad=True))\n",
        "        # self.linear_q = nn.Linear(in_features=model.config.n_ctx, out_features=self.model_weight_dims, bias=False)\n",
        "        # self.linear_k = nn.Linear(in_features=model.config.n_ctx, out_features=self.model_weight_dims, bias=False)\n",
        "        # self.linear_v = nn.Linear(in_features=model.config.n_ctx, out_features=self.model_weight_dims, bias=False)\n",
        "        # self.linear_o = nn.Linear(in_features=model.config.n_ctx, out_features=self.model_weight_dims, bias=False)\n",
        "        torch.nn.init.normal_(self.query_A, mean=0.0, std=1)\n",
        "        torch.nn.init.normal_(self.key_A, mean=0.0, std=1)\n",
        "        torch.nn.init.normal_(self.output_A, mean=0.0, std=1)\n",
        "        torch.nn.init.normal_(self.value_A, mean=0.0, std=1)\n",
        "\n",
        "\n",
        "    def forward(self, w_o, q_o, k_o, v_o):\n",
        "        # print((self.output_B).shape)\n",
        "        final_weight_WO = w_o + self.output_B.T @ self.output_A.T\n",
        "        final_weight_QO = q_o + self.query_B.T @ self.query_A.T\n",
        "        final_weight_KO = k_o + self.key_B.T @ self.key_A.T\n",
        "        final_weight_VO = v_o + self.value_B.T @ self.value_A.T\n",
        "        # out_q = self.linear_q(final_weight_QO)\n",
        "        # out_k = self.linear_k(final_weight_KO)\n",
        "        # out_v = self.linear_v(final_weight_VO)\n",
        "\n",
        "        # out_o\n",
        "        #\n",
        "        #\n",
        "        # = self.linear_o(final_weight_WO)\n",
        "\n",
        "        return final_weight_WO, final_weight_QO , final_weight_KO, final_weight_VO"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rhZE_9v5A1E7"
      },
      "outputs": [],
      "source": [
        "class LoRAWrapper(nn.Module):\n",
        "    def __init__(self) -> None:\n",
        "        super().__init__()\n",
        "        self.lora_layer = LoRALayer()\n",
        "        # self.linear = nn.Linear(in_features=model.config.vocab_size, out_features=2)\n",
        "        self.config = model.config\n",
        "\n",
        "    def forward(self, x):\n",
        "        qkv_layers = [model.transformer.h[i].attn.c_attn for i in range(self.config.n_layer)]\n",
        "        o_layers = [model.transformer.h[i].attn.c_proj for i in range(self.config.n_layer)]\n",
        "\n",
        "        for i in range(len(qkv_layers)):\n",
        "            hidden_size = qkv_layers[i].weight.size(-1) // 3\n",
        "            Q, K, V = torch.split(qkv_layers[i].weight, hidden_size, dim=-1)\n",
        "            O = o_layers[i].weight\n",
        "            out_o, out_q, out_k, out_v = self.lora_layer(O,Q,K,V)\n",
        "            combined_qkv = torch.concat([out_q, out_k, out_v], dim=-1)\n",
        "            # print(combined_qkv.shape)\n",
        "            # Update the model's attention weights\n",
        "            # # with torch.no_grad():\n",
        "            # qkv_layers[i].weight.copy_(combined_qkv)\n",
        "            # o_layers[i].weight.copy_(out_o)\n",
        "            # Assign the updated weights back to the model\n",
        "            qkv_layers[i].weight.data.copy_(combined_qkv)\n",
        "            o_layers[i].weight.data.copy_(out_o)\n",
        "        return model(x)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "OHy-iLFsA1E7"
      },
      "outputs": [],
      "source": [
        "class LoRAModel(nn.Module):\n",
        "    def __init__(self) -> None:\n",
        "        super().__init__()\n",
        "        self.lora_wrapper = LoRAWrapper()\n",
        "\n",
        "        self.config = model.config\n",
        "\n",
        "    def forward(self,x):\n",
        "\n",
        "        out = self.lora_wrapper(x)\n",
        "\n",
        "        return out\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kCgq4vbJA1E8",
        "outputId": "73a5b533-6d7b-43ee-8941-5b11a271043f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "LoRAModel(\n",
              "  (lora_wrapper): LoRAWrapper(\n",
              "    (lora_layer): LoRALayer()\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "lora_model = LoRAModel()\n",
        "lora_model.to(ModelArgs.device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "DyVywB38U7UN"
      },
      "outputs": [],
      "source": [
        "# final_model = outputLayer()\n",
        "# final_model.to(ModelArgs.device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hwBuMmZGA1E8",
        "outputId": "f0c50a07-bfb8-433c-a2ab-27e0bb69af37"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torchinfo in /usr/local/lib/python3.11/dist-packages (1.8.0)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "========================================================================================================================\n",
              "Layer (type (var_name))                  Input Shape          Output Shape         Param #              Trainable\n",
              "========================================================================================================================\n",
              "LoRAModel (LoRAModel)                    [1, 1024]            [1, 12, 1024, 64]    --                   True\n",
              "├─LoRAWrapper (lora_wrapper)             [1, 1024]            [1, 12, 1024, 64]    --                   True\n",
              "│    └─LoRALayer (lora_layer)            [768, 768]           [768, 768]           24,576               True\n",
              "│    └─LoRALayer (lora_layer)            [768, 768]           [768, 768]           (recursive)          True\n",
              "│    └─LoRALayer (lora_layer)            [768, 768]           [768, 768]           (recursive)          True\n",
              "│    └─LoRALayer (lora_layer)            [768, 768]           [768, 768]           (recursive)          True\n",
              "│    └─LoRALayer (lora_layer)            [768, 768]           [768, 768]           (recursive)          True\n",
              "│    └─LoRALayer (lora_layer)            [768, 768]           [768, 768]           (recursive)          True\n",
              "│    └─LoRALayer (lora_layer)            [768, 768]           [768, 768]           (recursive)          True\n",
              "│    └─LoRALayer (lora_layer)            [768, 768]           [768, 768]           (recursive)          True\n",
              "│    └─LoRALayer (lora_layer)            [768, 768]           [768, 768]           (recursive)          True\n",
              "│    └─LoRALayer (lora_layer)            [768, 768]           [768, 768]           (recursive)          True\n",
              "│    └─LoRALayer (lora_layer)            [768, 768]           [768, 768]           (recursive)          True\n",
              "│    └─LoRALayer (lora_layer)            [768, 768]           [768, 768]           (recursive)          True\n",
              "========================================================================================================================\n",
              "Total params: 24,576\n",
              "Trainable params: 24,576\n",
              "Non-trainable params: 0\n",
              "Total mult-adds (Units.MEGABYTES): 0\n",
              "========================================================================================================================\n",
              "Input size (MB): 0.01\n",
              "Forward/backward pass size (MB): 56.62\n",
              "Params size (MB): 0.10\n",
              "Estimated Total Size (MB): 56.73\n",
              "========================================================================================================================"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Printing a summary of the architecture\n",
        "!pip install torchinfo\n",
        "from torchinfo import summary\n",
        "input_ids = torch.randint(\n",
        "    0, model.config.vocab_size,\n",
        "    (1, model.config.n_ctx)\n",
        ").to(ModelArgs.device)\n",
        "# idx = idx.to(device)\n",
        "summary(model=lora_model,\n",
        "        input_data=input_ids,\n",
        "        col_names=[\"input_size\", \"output_size\", \"num_params\", \"trainable\"],\n",
        "        col_width=20,\n",
        "        row_settings=[\"var_names\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t72-kEcVA1E8",
        "outputId": "009aef8d-cbe0-4572-b38d-b280f5bf9246"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "==================================================================================================================================\n",
              "Layer (type (var_name))                            Input Shape          Output Shape         Param #              Trainable\n",
              "==================================================================================================================================\n",
              "GPT2LMHeadModel (GPT2LMHeadModel)                  [1, 1024]            [1, 12, 1024, 64]    --                   False\n",
              "├─GPT2Model (transformer)                          [1, 1024]            [1, 12, 1024, 64]    --                   False\n",
              "│    └─Embedding (wte)                             [1, 1024]            [1, 1024, 768]       (38,597,376)         False\n",
              "│    └─Embedding (wpe)                             [1, 1024]            [1, 1024, 768]       (786,432)            False\n",
              "│    └─Dropout (drop)                              [1, 1024, 768]       [1, 1024, 768]       --                   --\n",
              "│    └─ModuleList (h)                              --                   --                   --                   False\n",
              "│    │    └─GPT2Block (0)                          [1, 1024, 768]       [1, 1024, 768]       (7,087,872)          False\n",
              "│    │    └─GPT2Block (1)                          [1, 1024, 768]       [1, 1024, 768]       (7,087,872)          False\n",
              "│    │    └─GPT2Block (2)                          [1, 1024, 768]       [1, 1024, 768]       (7,087,872)          False\n",
              "│    │    └─GPT2Block (3)                          [1, 1024, 768]       [1, 1024, 768]       (7,087,872)          False\n",
              "│    │    └─GPT2Block (4)                          [1, 1024, 768]       [1, 1024, 768]       (7,087,872)          False\n",
              "│    │    └─GPT2Block (5)                          [1, 1024, 768]       [1, 1024, 768]       (7,087,872)          False\n",
              "│    │    └─GPT2Block (6)                          [1, 1024, 768]       [1, 1024, 768]       (7,087,872)          False\n",
              "│    │    └─GPT2Block (7)                          [1, 1024, 768]       [1, 1024, 768]       (7,087,872)          False\n",
              "│    │    └─GPT2Block (8)                          [1, 1024, 768]       [1, 1024, 768]       (7,087,872)          False\n",
              "│    │    └─GPT2Block (9)                          [1, 1024, 768]       [1, 1024, 768]       (7,087,872)          False\n",
              "│    │    └─GPT2Block (10)                         [1, 1024, 768]       [1, 1024, 768]       (7,087,872)          False\n",
              "│    │    └─GPT2Block (11)                         [1, 1024, 768]       [1, 1024, 768]       (7,087,872)          False\n",
              "│    └─LayerNorm (ln_f)                            [1, 1024, 768]       [1, 1024, 768]       (1,536)              False\n",
              "├─Linear (lm_head)                                 [1, 1024, 768]       [1, 1024, 50257]     (38,597,376)         False\n",
              "==================================================================================================================================\n",
              "Total params: 163,037,184\n",
              "Trainable params: 0\n",
              "Non-trainable params: 163,037,184\n",
              "Total mult-adds (Units.GIGABYTES): 163.34\n",
              "==================================================================================================================================\n",
              "Input size (MB): 0.01\n",
              "Forward/backward pass size (MB): 1261.05\n",
              "Params size (MB): 652.15\n",
              "Estimated Total Size (MB): 1913.21\n",
              "=================================================================================================================================="
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Printing a summary of the architecture\n",
        "from torchinfo import summary\n",
        "input_ids = torch.randint(\n",
        "    0, model.config.vocab_size,\n",
        "    (1, model.config.n_ctx)\n",
        ").to(ModelArgs.device)\n",
        "# idx = idx.to(device)\n",
        "summary(model=model,\n",
        "        input_data=input_ids,\n",
        "        col_names=[\"input_size\", \"output_size\", \"num_params\", \"trainable\"],\n",
        "        col_width=20,\n",
        "        row_settings=[\"var_names\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J7SFUmz1A1E8",
        "outputId": "f9e96ad0-b181-4768-a5f0-53e4229fd60f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total trainable parameters: 24576  which is:  0.015073861923424782 %\\ of 163037184 trainable params\n"
          ]
        }
      ],
      "source": [
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(\"Total trainable parameters:\", count_parameters(lora_model) ,\" which is: \" , (count_parameters(lora_model) / 163037184 )*100 , \"%\\ of\" , 163037184 , \"trainable params\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "eFlAvfbRA1E8"
      },
      "outputs": [],
      "source": [
        "# Optimizer setup and scheduler steup\n",
        "\n",
        "optimizer = torch.optim.AdamW(lora_model.parameters(), lr=ModelArgs.max_lr)\n",
        "# optimizer = torch.optim.Adam(model.parameters(), lr=max_lr, weight_decay=weight_decay_optim)\n",
        "initial_iters = 2000\n",
        "total_steps = 10000\n",
        "eval_iters = 100\n",
        "\n",
        "@torch.inference_mode()\n",
        "def estimate_loss():\n",
        "    out = {}\n",
        "    lora_model.eval()\n",
        "    for split in ['train', 'val']:\n",
        "        losses = torch.zeros(eval_iters)\n",
        "        for k in range(eval_iters):\n",
        "            idx, targets = get_batch(split=split)\n",
        "            logits = lora_model(idx).logits\n",
        "            batch_size, block_size, embeddings_dims = logits.shape\n",
        "            logits = logits.view(batch_size*block_size, embeddings_dims) # Total tokens(words) => batch_size * block_size\n",
        "            targets = targets.view(batch_size * block_size)\n",
        "            loss = nn.functional.cross_entropy(logits, targets)\n",
        "            losses[k] = loss.item()\n",
        "        out[split] = losses.mean()\n",
        "    lora_model.train()\n",
        "    return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZLpM5cmJA1E8",
        "outputId": "9d1e7081-cdec-4c4f-bcd2-ea36ebd3d046"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  1%|          | 101/10000 [01:49<60:29:47, 22.00s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "step 100: train loss 3.5244, val loss 3.4753\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  1%|          | 111/10000 [01:52<2:46:03,  1.01s/it]"
          ]
        }
      ],
      "source": [
        "#Train the  model\n",
        "from tqdm import tqdm\n",
        "\n",
        "lora_model.train()\n",
        "for step in tqdm(range(total_steps)):\n",
        "\n",
        "    # every once in a while evaluate the loss on train and val sets\n",
        "    if (step  % eval_iters == 0 and step != 0) or step == total_steps - 1:\n",
        "        losses = estimate_loss()\n",
        "        print(f\"step {step}: train loss {losses['train']:.4f}, val loss {losses['val']:.4f}\")\n",
        "\n",
        "\n",
        "    idx, targets = get_batch(split='train')\n",
        "    logits = lora_model(idx).logits\n",
        "    batch_size, block_size, embeddings_dims = logits.shape\n",
        "    logits = logits.view(batch_size*block_size, embeddings_dims)\n",
        "    targets = targets.view(batch_size * block_size)\n",
        "    loss = nn.functional.cross_entropy(logits, targets)\n",
        "    # print(loss.requires_grad)\n",
        "    loss.requires_grad = True\n",
        "    # print(count_parameters(lora_model))\n",
        "    # print(loss.requires_grad)\n",
        "    # break\n",
        "    optimizer.zero_grad(set_to_none=True)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    # print(loss.item())\n",
        "    # break\n",
        "\n",
        "    # if step != 0 and (step % eval_iters == 0 or step == total_steps -1) :\n",
        "    #     loss_values = estimate_loss()\n",
        "    #     print(\"Train Loss at {} steps : {}\".format(step, loss.item()), \"Val Loss at {} steps : {}\".format(step, loss_values['val']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8uH1lR8rOGNk"
      },
      "outputs": [],
      "source": [
        "for name, param in lora_model.named_parameters():\n",
        "    print(f\"{name}: requires_grad={param.requires_grad}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ICAPXdFLpEXr"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
